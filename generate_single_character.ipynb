{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54afb2a8",
   "metadata": {},
   "source": [
    "# Generate a single [character.ai](https://beta.character.ai/) character definition\n",
    "\n",
    "This example shows how to generate the character definition of a single [character.ai](https://beta.character.ai/) character from a corpus. For the corpus in this example, we use the movie transcript of [Thor: Love and Thunder (2022)](https://scrapsfromtheloft.com/movies/thor-love-and-thunder-transcript/).\n",
    "\n",
    "To generate your own character definition:\n",
    "1. Put the corpus into a single a `.txt` file inside the `data/` directory.\n",
    "2. Assign the name of the `.txt` file to the `CORPUS` constant below.\n",
    "3. Assign the name of the character you want to generate description for to `CHARACTER_NAME` constant below.\n",
    "4. Run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c5d195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS = 'data/thor_love_and_thunder.txt'\n",
    "CHARACTER_NAME = \"Jane Foster\"  # the name of the character we want to generate a description for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da765a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import asdict\n",
    "import json\n",
    "import os\n",
    "\n",
    "from data_driven_characters.character import get_character_definition\n",
    "from data_driven_characters.corpus import get_characters, get_corpus_summaries, load_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8298d68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directories to cache results and intermediate outputs\n",
    "SUMMARY_TYPE = \"map_reduce\"  # summarize each chunk of the corpus independently\n",
    "OUTPUT_ROOT = \"output\"\n",
    "corpus_name = os.path.splitext(os.path.basename(CORPUS))[0]\n",
    "output_dir = f\"{OUTPUT_ROOT}/{corpus_name}/summarytype_{SUMMARY_TYPE}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "summaries_dir = f\"{output_dir}/summaries\"\n",
    "character_definitions_dir = f\"{output_dir}/character_definitions\"\n",
    "os.makedirs(character_definitions_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf9e861",
   "metadata": {},
   "source": [
    "## Summarization\n",
    "Because the entire corpus does not fit in the context length of the LLM, we split it into a list of chunks.\n",
    "We turn the list of chunks into a list of summaries using one of [LangChain's summarization chains](https://langchain-langchain.vercel.app/docs/modules/chains/document/).\n",
    "\n",
    "If `SUMMARY_TYPE = 'refine'`, we first summarize the first chunk, and then each subsequent summary is generated from the previous summary and the current chunk.\n",
    "If `SUMMARY_TYPE = 'map_reduce'`, we summarize each chunk independently.\n",
    "\n",
    "Because the summaries are expensive to generate, they are cached in `summaries_dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f72b8d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summaries already exist. Loading summaries.\n"
     ]
    }
   ],
   "source": [
    "# split corpus into a set of chunks\n",
    "docs = load_docs(\n",
    "    corpus_path=CORPUS,\n",
    "    chunk_size=2048,  # number of tokens per chunk\n",
    "    chunk_overlap=64,  # number of tokens of overlap between chunks\n",
    ")\n",
    "\n",
    "# generate summaries\n",
    "corpus_summaries = get_corpus_summaries(docs=docs, summary_type=SUMMARY_TYPE, cache_dir=summaries_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f116f3",
   "metadata": {},
   "source": [
    "## Generate [character.ai](https://beta.character.ai/) character definition\n",
    "Based on the corpus, we can now generate the elements - name, short description (50 characters), long description (500 characters), and custom greeting - that are required to [create a character.ai character](https://beta.character.ai/editing). These character definitions are cached in `character_definitions_dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45d827ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_definition = get_character_definition(\n",
    "        name=CHARACTER_NAME,\n",
    "        corpus_summaries=corpus_summaries,\n",
    "        cache_dir=character_definitions_dir,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce604024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"Jane Foster\",\n",
      "    \"short_description\": \"I'm Jane Foster, fighting cancer & evil.\",\n",
      "    \"long_description\": \"I am Jane Foster, a determined woman battling stage four cancer, yet fighting alongside Thor against the evil God Butcher, Gorr. My deep connection with Thor strengthens our resolve. As the Mighty Thor, I wield Mjolnir, despite its draining effect. Fiercely independent, I refuse help from close friends. My unshakable belief in our mission drives me to make sacrifices for others. Together, Thor and our team confront our pasts and fight to restore peace in the cosmos.\",\n",
      "    \"greeting\": \"Hi there, I'm Jane. Ready to take on whatever challenges come our way?\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(asdict(character_definition), indent=4))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
